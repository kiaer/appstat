\documentclass{article}
\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{caption}
\usepackage[table]{xcolor}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{parskip}
\usepackage{url}
\usepackage{float}
\usepackage{enumitem} 
\usepackage{amstext}
\usepackage{fancybox}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[bottom]{footmisc}
\usepackage{hyperref}
\linespread{1.3}
\usepackage{datenumber}


\pagestyle{fancy}
\fancyhf{}
\setlength{\parindent}{0pt}

\setlength{\headheight}{15pt}
\setlength{\headsep}{25pt}
\lhead{Applied Statistics and Statistical Software (02441) - Case 1}
\rhead{\today}
\cfoot{Page \thepage{} of \pageref{LastPage}}

\title{
\HRule \\
\textsc{\doctitle} \\
	 \small{\textsl{\docsubtitle}}
\HRule\\
}
\author{\docauthor\\\small{\docplace}}
\date{\docdate}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\begin{document}
\begin{titlepage}
\begin{center}
\textsc{\LARGE 02441 -  Applied Statistics and Statistical Software \\Winter 2018}\\[1.5cm]
\textsc{\large Technical Univeristy of Denmark}\\[0.5cm]
\HRule \\[0.4cm]
{ \huge \bfseries Case 1}\\[0.1cm]
\HRule \\[1.5cm]
\end{center}
\begin{flushleft} \large
\emph{Author:}\\
Christian Mathias Rohde \textsc{Ki??r}: s123812\\
Per Anton \textsc{Almgren}: s170464\\
Kristian \textsc{Maar}: s172956
\end{flushleft}
\vfill
\begin{flushleft} \large

\end{flushleft}
\vfill
\begin{center}
{\large \today}
\end{center}
\end{titlepage}
\newpage
\section*{Summary}

\newpage
\tableofcontents
\newpage
<<echo=FALSE, results='hide', cache=FALSE>>=
det <- read.table("SPR.txt",header=TRUE, colClasses = c("factor", "numeric", "numeric", "factor", "numeric", "factor", "factor"))
det$RunDate <- factor(det$RunDate,
                      labels = c("25/11/2008","27/11/2008", "3/12/2008", "5/12/2008", "8/12/2008"))
lm1 <- lm(Response ~ RunDate+Cycle+Enzyme*EnzymeConc+DetStock+CaStock, det)
library(xtable)
library(MASS)
@

\section{Introduction}


An effective washing method is not only a matter of competitive edge and potential revenue for companies producing detergent and laundry products, it also provides benefits for the end consumer by offering possible reductions in both household economic and environmental impact while performing a crucial and daily task. The performance of different detergents is believed to be correlated to a range of variables such as enzymatic activity which is a catalytic process that involves the enzymatic breakdown of various staining compounds. There are many different enzymes with different properties and potential with regards to usefulness in removing stains from textiles and the presence or absence of other compounds may influence the cleaning performance both positively or negatively. 
The aim of this report is to analyze the data obtained from an experiment conducted in November and December 2008. The dataset contains results from the testing of 5 different enzymes at different concentrations. The effects of the presence or absence of a detergent and Calcium ions are also investigated with all 5 enzymes. This analysis will attempt to reject or confirm all possible correlations between the variable combinations of enzymes, detergent and Calcium-ions. The preliminary assumption is that the cleaning solutions applied in the experiment have no significant effect on the response of an experimental proteinfilm that substitutes for a theoretical stain on a textile. If the data provided are in contradiction with this assumption we will use statistical modelleing to further reveal the possible correlations and make inference about the results.


\underline{The process will involve specifically:}


- A general interpretation of the data. 

- Determining if Calcium-ions and detergent affect the catalytic activity.

- Determining to what extend the catalytc activity is dependant upon enzyme concentration.

- Comparing the performance of the individual enzymes and showing what enzyme performed best and which performed poorest in the experiment.

- Scrutenizing the dataset and methodology for indications of systematic error a discussion of the possible effects on the statistical analysis and an evaluation of the overall validity of the results.



\section{Case Description}

The dataset contains 160 individual measurements performed during 5 days from November 25th to December 8th 2008. On each individual day only one of the total 5 enzymes was tested. The performance of each enzyme was tested in the presence and absence of detergent and Calcium ions as well as the presence or absence of the combination of both detergent and Calcium-ions. The replications of the experiment for the various combinations of variable was conducted in random order within the cycle. The data for each replication of the experiment yields the following variables:

RunDate:      Date of the experiment. (YMMDD)

Cycle:        Cycle number of the particular replicant within the cycle.

Response:     Amount of Protein removed in RU. (10^-^6  g/m^2)

Enzyme:       Identifying the particular enzyme. (A,B,C,D or E)

EnzymeConc:   Enzyme concentration in nM.  (0, 2.5, 7.5 15)
=======
\section{Case Description}

Description of data (Table)
>>>>>>> 7cb22d3ccb5fa0ac181b302902233125174cabdd

DetStock:     With or without detergent. (+ or 0)

CaStock:      With or without Calcium ions. (+ or 0)



The sum of replications yields a total of 160 observations divided evenly among the enzymes giving 32 replications pr. enzyme and 32 coinciding replications of the experiment on each of the 5 days. The number of replications pr. enzyme is sufficient to perform statistical analysis. The mitigation of systematic error is strengthened by randomizing the succesion of the variyng testsolutions throughout the individual days. Each unique combination of enzyme, enzyme concentration, detergent and calcium ions is measured twice, which enhances the strength of the data. However as each enzyme is only tested on one particular day and no two enzymes are tested on the same day there could possibly be a skew in the data from each day due to temporal variation in the experimental conditions. As the experiment isolates the all replications of the individual enzymes to a single day, any systematic error could make a difference in enzyme response indistinguishable from any systematic error arising from conditions particular to the different days. 




<<initSum, results='asis', echo=FALSE>>=
xtable(summary(det), caption = "Summary of the data showing an even distribution of replications among the variables with 32 replications pr. day and 32 replications pr. enzyme. Though the table only shows that calcium ions and detergent was present in half the replications further scrutiny of the data reveals that all the possible presence/absence combinations are evenly distributed. While the range of response is from 0.1 to 1588 the mean = 431.6 and median = 322.4 suggests that the dataset is skewed towards lower response values as the median is significantly lower than the mean. - The Cycle and EnzymeConc values are irrelevant in the table above as the numeric values are discrete and therefors are better interpreted as factors.", label = "tab:sum")
@

<<barplotinit, echo=FALSE, fig.height=4, fig.pos="H", fig.cap="Barplot showing an overview of the response values of the different enzymes and different concentrations. The plot suggests a general trend of higher response values at higher concentrations. Enzyme A also seem to exhibit the highest performance.">>=
par(mfrow=c(1,1))
barplot(tapply(det$Response,list(det$EnzymeConc, det$Enzyme),mean),beside=TRUE, xlab="Enzymes", ylab="Response", col=c("snow1", "snow2", "snow3", "snow4") )
legend(16, 1000, col=c("snow1", "snow2", "snow3", "snow4"),legend =  c("0 nM", "2.5 nM", "7.5 nM", "15 nM"), lty = 1)
@

<<boxplotInit, echo=FALSE, fig.height=5, fig.pos="H", fig.cap= " (Top) Boxplot showing the response values at the different enzyme concentrations. There seems to be a significant increase in response mean values at higher enzyme concentrations. (Bottom) Boxplot showing the response values of the different enzymes. When comparing the mean values the plot seems to suggest that enzyme A outperforms the other 4 enzymes and enzyme E could also have significantly higher responses than enzymes B, C and D. While enzyme B and C show comparable responses, enzyme D seem to perform poorest ">>=
par(mfrow=c(2,1),mar=c(3,3,2,1),mgp=c(2,0.7,0))
boxplot(Response ~ EnzymeConc,det, xlab="Enzyme Concentration", ylab="Response")
boxplot(Response ~ Enzyme, det, xlab="Enzymes", ylab="Response")
@


<<echo=FALSE, results='hide'>>=
det$Rpower <- det$Response^0.4
det$concpow <- det$EnzymeConc^0.4
lm4<- step(lm(Rpower ~ RunDate+Cycle+Enzyme*concpow+DetStock+CaStock, det, subset = -147))
@

<<plots showing outlier, echo=FALSE, fig.height=5, fig.pos="H" , fig.cap="Plots showing the mean value and residuals for all enzymes when in concentration of 2.5 nM and detergent present. Enzyme E is also presented without the suspected outlier.">>=
test<-subset.data.frame(det,det$DetStock=="Det+" & det$EnzymeConc==2.5)
par(mfrow=c(2,3))
plot(1:4,testA<-subset(test$Response,test$Enzyme=="A"),ylab="Response"
     ,xlab="Measurement No.",ylim=c(150,1000))
title('Enzyme A')
abline(mean(testA),0)
for(i in 1:4) lines(c(i,i),c(mean(testA),testA[i]))

plot(1:4,testB<-subset(test$Response,test$Enzyme=="B"),ylab="Response"
     ,xlab="Measurement No.",ylim=c(150,1000))
title('Enzyme B')
abline(mean(testB),0)
for(i in 1:4) lines(c(i,i),c(mean(testB),testB[i]))

plot(1:4,testC<-subset(test$Response,test$Enzyme=="C"),ylab="Response"
     ,xlab="Measurement No.",ylim=c(150,1000))
title('Enzyme C')
abline(mean(testC),0)
for(i in 1:4) lines(c(i,i),c(mean(testC),testC[i]))

plot(1:4,testD<-subset(test$Response,test$Enzyme=="D"),ylab="Response"
     ,xlab="Measurement No.",ylim=c(150,1000))
title('Enzyme D')
abline(mean(testD),0)
for(i in 1:4) lines(c(i,i),c(mean(testD),testD[i]))

plot(1:4,testE<-subset(test$Response,test$Enzyme=="E"),ylab="Response"
     ,xlab="Measurement No.",ylim=c(150,1000))
title('Enzyme E')
abline(mean(testE),0)
for(i in 1:4) lines(c(i,i),c(mean(testE),testE[i]))

plot(c(1,2,4), e2<-testE[c(1,2,4)],ylab="Response"
     ,xlab="Measurement No.",ylim=c(150,1000))
title('Enzyme E- measurement 147')
abline(mean(e2),0)
for(i in c(1,2,4)) lines(c(i,i),c(mean(e2),testE[i]))

@

<<Normality, echo=FALSE,fig.cap="figurtekst", fig.height=4>>=
library(car)
qqPlot(det$Response)
@
\section{Analysis}
<<boxcox, echo=FALSE, fig.height=5, out.width='.9\\linewidth', fig.cap="Boxcox Transformation of LM1", fig.pos="H">>=
boxcox(lm1, lambda = seq(-0.5, 1, length.out = 20), data=det)
@
When analyzing the data the Principle of Parsimony is applied. This means that the aim is to describe the data by the simplest model possible. Therefore a linear model is set up, as this is the simplest form to model data. In order to set up a linear model, the data needs to be normally distributed, and as this is not the case a transformation of some of the data is needed. To investigate this a linear model is set up:
<<lm1, echo=TRUE>>=
lm1 <- lm(Response ~ RunDate+Cycle+Enzyme*EnzymeConc+DetStock+CaStock, det)
@

This model is a maximal model using all explanatory variables to model the response in the experiments. To find the appropriate transformation a boxcox plot is made (figure \ref{boxcox}), and based on this a transformation of the response observarions using the power of 0.4 is chosen. Now a new linear model is formed using the new transformation. Further analysis of residuals vs. leverage in the new model showed that a transformation of the enzyme concentrations would be appropriate. Now the power of 0.4 is also applied to the enzyme concentrations and another model is set up using this as well. When analyzing this model an outlier becomes apparent. This is observation 147:
<<147, results='asis',echo=FALSE>>=
xtable(det[147,1:7], caption = "Outlier observation 147", label = "tab:147")
@

To look further into this observation, and decide whether it is to be excluded from the data set or not, it is compared to the other measurements made under the same conditions. This is an enzyme concentration of 2.5 nM with detergent present as seen in table \ref{tab:147}. The hardness of the water is not taken into account, as an anova analysis has proven this to be of no statistical significance with a p-value of 0.4257. (See further in Results) In figure \ref{test147} mean values of the response for all enzymes are plotted together with the residuals to investigate the variance of the measurements. Enzyme E is also plotted without observation 147. When comparing the different variances the variance of enzyme E stands out a lot, and after removing observation 147 the variance is in the same order of magnitude as the other measurements. This leads to the decision to exclude this outlier.

Now there is a maximal linear model, and following the principle of parsimony this is now to be reduced into a minimal adequate model. This is done by step wise removing insignificant explanatory variables until only statistically significant variables, and interactions between variables, are included in the model. The final model is summarized in table \ref{tab:sum} in the next section.

2)Transformation - Description

3)Investigation and explanation concerning outliers in the data, what we do and why.

4) Choice of model and reasoning/arguments behind our choice

<<diagnostics, echo=FALSE, fig.cap="Diagnostics plot of LM4", fig.pos="H">>=
par(mfrow=c(2,2))
plot(lm4, col=as.numeric(as.factor(det$EnzymeConc[-147])))
@

\section{Results}

As a result of the analysis, the linear mode

<<summary, results='asis'>>=
xtable(summary(lm4), caption = "Summary of the linear model", label = "tab:sum")
@

<<anova, results='asis'>>=
xtable(anova(lm4), caption = "Anova tabel", label = "tab:anova")
@

<<drop1, results='asis'>>=
xtable(drop1(lm4, test="F"), caption = "Drop 1 tabel with F-test", label = "tab:drop1", table.placement="H")
@
\newpage
<<enzymede, echo=FALSE, fig.height=6, out.width='.9\\linewidth', fig.pos="H">>=
pred.d<-expand.grid(Enzyme=levels(det$Enzyme), concpow=seq(0,3, 0.2), DetStock="Det0", CaStock="Ca0")
pred<-predict(lm4,pred.d,int="c")^(5/2) # Predictions on original scale
# Plotting
par(mfrow=c(1,2))
matplot(c(0,15),range(pred),type="n",ylim=c(0,2000), ylab="Response", xlab="Concentration", main="Det0")
matlines((0:15), cbind(matrix(pred[,1],nrow=16,byrow=TRUE),matrix(pred[,2],nrow=16,byrow=TRUE),matrix(pred[,3],nrow=16,byrow=TRUE)),col=2:6,lty=rep(c(1,2,2),each=5),lwd=1)
legend("topleft",legend=levels(det$Enzyme),lty=1,col=2:6)

pred.d<-expand.grid(Enzyme=levels(det$Enzyme),concpow=seq(0,3,0.2),DetStock="Det+", CaStock="Ca0")
pred<- predict(lm4,pred.d,int="c")^(5/2) # Predictions on original scale
matplot(c(0,15),range(pred),type="n",ylim=c(0,2000), ylab="Response", xlab="Concentration", main="Det+")
matlines(0:15, cbind(matrix(pred[,1],nrow=16,byrow=TRUE),matrix(pred[,2],nrow=16,byrow=TRUE),matrix(pred[,3],nrow=16,byrow=TRUE)),col=2:6,lty=rep(c(1,2,2),each=5),lwd=1)
legend("topleft",legend=levels(det$Enzyme),lty=1,col=2:6)
@

\section{Discussion}

Systematic errors - Discussion of 0 Enzyme, 0 Detergent variable data, and analysis of variance of the results. 

Systematic errors - can we compare the 2 sets of 0 value replications??? E.g. by splitting the data?

<<control, echo=FALSE>>=
control <- subset(det$Response, det$EnzymeConc == 0.0 & det$DetStock == "Det0")
par(mfrow=c(1,1), mar=c(3.3,3.3,1.5,1), mgp=c(2,0.7,0))

EnzymeType <- subset(det$Enzyme, det$EnzymeConc == 0.0 & det$DetStock == "Det0")
fit <- aov(control ~ EnzymeType, data = det)
@

<<Controlsamples,fig.cap="Boxplot of samples with no Enzyme, Ca. or Det.", echo=FALSE, fig.pos="h!", fig.height=4>>=
plot(EnzymeType, control,ylab="Response", xlab="Enzyme")
@

<<aov, results="asis", echo=FALSE>>=
xtable(aov(control ~ EnzymeType, data = det), caption = "Analysis of variance tabel", label = "tab:aov")
@


\section{Conclusion}



\end{document}
